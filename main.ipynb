{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "from datetime import UTC, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from imblearn.pipeline import Pipeline as PL\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skew the data to 50/50\n",
    "\n",
    "data = pd.read_csv(\"data/Loan_default.csv\")\n",
    "data = shuffle(data)\n",
    "out = []\n",
    "for idx, j in enumerate(data[\"Default\"]):\n",
    "    if j == (len(out) % 2):\n",
    "        out.append(data.iloc[idx])\n",
    "\n",
    "\n",
    "data = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Data will be all of it\n",
    "data = pd.read_csv(\"data/Loan_default_50k.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"LoanID\", \"Default\"], axis=1)\n",
    "y = data[\"Default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"Education\",\n",
    "    \"EmploymentType\",\n",
    "    \"MaritalStatus\",\n",
    "    \"HasMortgage\",\n",
    "    \"HasDependents\",\n",
    "    \"LoanPurpose\",\n",
    "    \"HasCoSigner\",\n",
    "]\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "        (\"cat\", OneHotEncoder(), categorical_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_hyper = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "        \"params\": {\n",
    "            \"penalty\": [\"l1\", \"l2\", None],\n",
    "            \"fit_intercept\": [True, False],\n",
    "            \"intercept_scaling\": [0.1, 1, 10],\n",
    "            \"dual\": [True, False],\n",
    "            \"C\": [i/10 for i in range(0,50,5)]\n",
    "        },\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [100, 200, 300],\n",
    "            \"learning_rate\": [0.001, 0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 12, 22, 35, 10],\n",
    "        },\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": range(10,500,10),\n",
    "            \"max_depth\": [None, 10, 20, 30],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"min_samples_leaf\": [1, 2, 4],\n",
    "            \"bootstrap\": [True, False],\n",
    "        },\n",
    "    },\n",
    "    \"XGB Classifier\": {\n",
    "        \"model\": XGBClassifier(random_state=42),\n",
    "        \"params\": {\"n_estimators\": [100, 200, 300], \"learning_rate\": [0.001, 0.01, 0.1, 0.2], \"max_depth\": [3, 5, 10]},\n",
    "    },\n",
    "}\n",
    "strat = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch (Takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "scorer = make_scorer(f1_score)\n",
    "for name, model in models_hyper.items():\n",
    "    print(f\"Starting {name}\")\n",
    "    starting = datetime.now(tz=UTC).timestamp()\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model[\"model\"],\n",
    "        param_grid=model.get(\"params\", {}),\n",
    "        scoring=scorer,\n",
    "        cv=strat,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    models.update({name: grid_search.best_estimator_})\n",
    "    print(f\"It took {datetime.now(tz=UTC).timestamp()-starting} seconds\")\n",
    "    print(f\"{name} Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{name} Best Score: {grid_search.best_score_}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Found Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the \"Optimal\" Models that we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = [\n",
    "    {\n",
    "        \"Name\": \"LogisticRegression\",\n",
    "        \"Model\": LogisticRegression,\n",
    "        \"Best Params\": {\n",
    "            \"intercept_scaling\": 0.1,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"GradientBoostingClassifier\",\n",
    "        \"Model\": GradientBoostingClassifier,\n",
    "        \"Best Params\": {\n",
    "            \"learning_rate\": 0.2,\n",
    "            \"max_depth\": 3,\n",
    "            \"min_samples_leaf\": 10,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"RandomForestClassifier\",\n",
    "        \"Model\": RandomForestClassifier,\n",
    "        \"Best Params\": {\n",
    "            \"max_depth\": 20,\n",
    "            \"min_samples_split\": 5,\n",
    "            \"n_estimators\": 200,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"XGBClassifier\",\n",
    "        \"Model\": XGBClassifier,\n",
    "        \"Best Params\": {\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"max_depth\": 3,\n",
    "            \"n_estimators\": 200,\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "models = {mod[\"Name\"]:mod[\"Model\"](**mod[\"Best Params\"]) for mod in opt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = {}\n",
    "res = {}\n",
    "confusion_matrices = {}\n",
    "roc_data = {}\n",
    "\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Working on {name}\")\n",
    "    pipeline = PL([(\"preprocessor\", preprocessor), (\"smote\", SMOTE(random_state=42)), (\"classifier\", model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(pipeline, \"predict_proba\") else None\n",
    "    cv_scores[name] = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "\n",
    "    res[model] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"AUC-ROC\": roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc_score = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    roc_data[model] = {\"fpr\": fpr, \"tpr\": tpr, \"auc\": auc_score}\n",
    "    confusion_matrices[model] = confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print those cool plots for our presi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  figure_data = pd.read_csv(open(\"figs/out.csv\"))\n",
    "\n",
    "  data_points = set(figure_data[\"Model\"].values)\n",
    "  points = []\n",
    "  for i in data_points:\n",
    "      points.append(figure_data.where(figure_data[\"Model\"] == i).dropna())\n",
    "\n",
    "  import plotly.express as px\n",
    "  for i in points:\n",
    "    fig = px.line_polar(i, r=\"Points\",\n",
    "                        theta=\"Catagory\",\n",
    "                        color=\"Model\",\n",
    "                        line_close=True,\n",
    "                        template=\"plotly_dark\",\n",
    "                        range_r=[0, 100]\n",
    "                        )\n",
    "\n",
    "    fig.update_polars(angularaxis_showgrid=False,\n",
    "                      radialaxis_gridwidth=0,\n",
    "                      bgcolor=\"#494b5a\",\n",
    "                      gridshape='linear',\n",
    "                      radialaxis_showticklabels=False\n",
    "                      )\n",
    "\n",
    "    fig.update_layout(paper_bgcolor=\"#2c2f36\")\n",
    "    fig.show()\n",
    "\n",
    "  fig = px.line_polar(x, r=\"Points\",\n",
    "                      theta=\"Catagory\",\n",
    "                      color=\"Model\",\n",
    "                      line_close=True,\n",
    "                      range_r=[0, 100],\n",
    "                      template=\"plotly_dark\")\n",
    "\n",
    "  fig.update_polars(angularaxis_showgrid=False,\n",
    "                    radialaxis_gridwidth=0,\n",
    "                    bgcolor=\"#494b5a\",\n",
    "                      gridshape='linear',\n",
    "                    radialaxis_showticklabels=False\n",
    "                    )\n",
    "\n",
    "  fig.update_layout(paper_bgcolor=\"#2c2f36\")\n",
    "  fig.show()\n",
    "except ImportError:\n",
    "  print(\"You don't have plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print CV Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Mean AUC Score: 0.3320\n",
      "Standard Deviation of Scores: 0.002\n",
      "T-Statistic: -155.60\n",
      "P-Value: 0.0000000102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in cv_scores:\n",
    "    mean_score = np.mean(cv_scores[idx])\n",
    "    std_score = np.std(cv_scores[idx])\n",
    "\n",
    "    t_stat, p_value = ttest_1samp(cv_scores[idx], 0.5)\n",
    "\n",
    "\n",
    "    print(f\"Mean AUC Score: {mean_score:.4f}\")\n",
    "    print(f\"Standard Deviation of Scores: {std_score:.3f}\")\n",
    "    print(f\"T-Statistic: {t_stat:.2f}\")\n",
    "    print(f\"P-Value: {p_value:.10f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print actual bar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in res:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.barh(res[metric].keys(), res[metric].values(), color=\"lightblue\")\n",
    "    plt.title(metric)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    for bar, score in zip(bars, res[metric].values(), strict=False):\n",
    "        plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2, f\"{score:.3f}\", va=\"center\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a table with the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = [\"Accuracy\", \"AUC-ROC\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "\n",
    "model_names = list(res.keys())\n",
    "scores = np.array([[res[model][metric] for metric in metrics] for model in model_names])\n",
    "\n",
    "df_results = pd.DataFrame(scores, index=model_names, columns=metrics)\n",
    "\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Con Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (name, cm) in confusion_matrices.items():\n",
    "    plt.plot(3, 3)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 30})\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
